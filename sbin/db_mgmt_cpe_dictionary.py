#!/usr/bin/env python3
#
# Import script of nvd cpe (Common Platform Enumeration) definition
# into a collection used for human readable lookup of product name.
#
# Imported in cvedb in the collection named cpe.
#
# The format of the collection is the following
#
# { "_id" : ObjectId("50a2739eae24ac2274eae7c0"), "id" :
# "cpe:/a:1024cms:1024_cms:0.7", "title" : "1024cms.org 1024 CMS 0.7" }
#
# Software is free software released under the "GNU Affero General Public License v3.0"
#
# Copyright (c) 2012 		Wim Remes
# Copyright (c) 2012-2018  Alexandre Dulaunoy - a@foo.be
# Copyright (c) 2014-2018  Pieter-Jan Moreels - pieterjan.moreels@gmail.com

import argparse
import hashlib
import json

# Imports
import os
import shutil
import sys
import tempfile
import zipfile
from io import BytesIO

import ijson
from pymongo import UpdateOne

from lib.DownloadHandler import DownloadHandler

runPath = os.path.dirname(os.path.realpath(__file__))
sys.path.append(os.path.join(runPath, ".."))

from dateutil.parser import parse as parse_datetime
from lib.Config import Configuration
import lib.DatabaseLayer as db
from lib.Toolkit import generate_title

last_modified = None

# parse command line arguments
argparser = argparse.ArgumentParser(
    description="populate/update the local CPE database"
)
argparser.add_argument("-u", action="store_true", help="update the database")
argparser.add_argument("-p", action="store_true", help="populate the database")
argparser.add_argument(
    "-a", action="store_true", default=False, help="force populating the CPE database"
)
argparser.add_argument(
    "-f", action="store_true", default=False, help="force update of the CPE database"
)
argparser.add_argument("-v", action="store_true", help="verbose output")
args = argparser.parse_args()


def process_cpe_item(item=None):
    if item is None:
        return None
    if "cpe23Uri" not in item:
        return None

    cpe = {}
    cpe["title"] = generate_title(item["cpe23Uri"])
    cpe["cpe_2_2"] = item["cpe23Uri"]
    cpe["cpe_name"] = item["cpe_name"]
    version_info = ""
    if "versionStartExcluding" in item:
        cpe["versionStartExcluding"] = item["versionStartExcluding"]
        version_info += cpe["versionStartExcluding"]
    if "versionStartIncluding" in item:
        cpe["versionStartIncluding"] = item["versionStartIncluding"]
        version_info += cpe["versionStartIncluding"]
    if "versionEndExcluding" in item:
        cpe["versionEndExcluding"] = item["versionEndExcluding"]
        version_info += cpe["versionEndExcluding"]
    if "versionEndIncluding" in item:
        cpe["versionEndIncluding"] = item["versionEndIncluding"]
        version_info += cpe["versionEndIncluding"]

    sha1_hash = hashlib.sha1(
        cpe["cpe_2_2"].encode("utf-8") + version_info.encode("utf-8")
    ).hexdigest()
    cpe["id"] = sha1_hash

    return cpe


class CPEDownloads(DownloadHandler):
    def __init__(self):
        super().__init__()

        self.feed_url = Configuration.getFeedURL("cpe")

    def download_site(self, url):
        global last_modified
        print("Downloading: {}".format(url))
        session = self.get_session()
        with session.get(url) as response:
            last_modified = parse_datetime(
                response.headers["last-modified"], ignoretz=True
            )

            i = db.getInfo("cpd")

            if i is not None:
                if last_modified == i["last-modified"] and not args.f:
                    print("CPE's are not modified since the last update")
                    return

            print("Read {} from {}".format(len(response.content), url))
            wd = tempfile.mkdtemp()
            filename = os.path.join(wd, url.split("/")[-1][:-4])
            print("Saving file to: {}".format(filename))

            with zipfile.ZipFile(BytesIO(response.content)) as zip_file:
                zip_file.extractall(wd)

            self.stream_json(filename=filename)

    def stream_json(self, filename):
        bulk_commands = []
        with open(filename, "rb") as input_file:
            x = 1
            for cpe in ijson.items(input_file, "matches.item"):
                print("Processing cpe {} of {}".format(x, "UNK"))
                bulk_commands.append(self.process_cpes(cpeitem=cpe))
                x += 1

            self.process_chunks_in_function(self.do_update, self.chunk_list(bulk_commands, 10000))

            print("Finished processing file: {}".format(filename))

        shutil.rmtree(filename)

    def do_update(self, lst):

        db.bulkUpdate("cpe", lst, len(lst))

    def process_cpes(self, cpeitem):
        cpe = process_cpe_item(cpeitem)
        return UpdateOne({"id": cpe["id"]}, {"$set": cpe}, upsert=True,)

    def update(self, **kwargs):

        self.process_downloads([self.feed_url])

    def populate(self, **kwargs):
        self.update()


if __name__ == "__main__":
    if args.u:

        cpd = CPEDownloads()

        cpd.update()

        # update database info after successful program-run
        db.setColUpdate("cpe", last_modified)
    elif args.p:
        c = db.getSize("cpe")
        if args.v:
            print(str(c))
        if c > 0 and args.a is False:
            print("Database already populated")
        else:
            print("Database population started")
            db.dropCollection("cpe")

            cpd = CPEDownloads()
            cpd.update()

            # update database info after successful program-run
            db.setColUpdate("cpe", last_modified)
